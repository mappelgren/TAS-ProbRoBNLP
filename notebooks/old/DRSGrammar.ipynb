{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbe4b49-1b04-420b-b238-1779ee1286f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-473d878506aa>:4: DeprecationWarning: \n",
      "  Function parseLexicon() has been deprecated.  Use fromstring()\n",
      "  instead.\n",
      "  lex = lexicon.parseLexicon('''\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from nltk.ccg import chart, lexicon\n",
    "\n",
    "\n",
    "lex = lexicon.parseLexicon('''\n",
    "       :- S, NP, N, VP\n",
    "    \n",
    "        Det :: NP/N\n",
    "        Pro :: NP\n",
    "         Modal :: S\\\\NP/VP\n",
    "    \n",
    "         TV :: VP/NP\n",
    "         DTV :: TV/NP\n",
    "    \n",
    "         the => Det\n",
    "    \n",
    "         that => Det\n",
    "         a => Det\n",
    "         the => Det\n",
    "         that => NP\n",
    "    \n",
    "         I => Pro\n",
    "         you => Pro\n",
    "         we => Pro\n",
    "    \n",
    "         chef => N\n",
    "         cake => N\n",
    "         children => N\n",
    "         dough => N\n",
    "    \n",
    "         will => Modal\n",
    "         should => Modal\n",
    "         might => Modal\n",
    "         must => Modal\n",
    "    \n",
    "         and => var\\\\.,var/.,var\n",
    "    \n",
    "         to => VP[to]/VP\n",
    "    \n",
    "         without => (VP\\\\VP)/VP[ing]\n",
    "    \n",
    "         be => TV\n",
    "         cook => TV\n",
    "         eat => TV\n",
    "    \n",
    "         cooking => VP[ing]/NP\n",
    "    \n",
    "         give => DTV\n",
    "    \n",
    "         is => (S\\\\NP)/NP\n",
    "        prefer => (S\\\\NP)/NP\n",
    "    \n",
    "        which => (N\\\\N)/(S/NP)\n",
    "    \n",
    "         persuade => (VP/VP[to])/NP\n",
    "        ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "23918ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbcac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. hook \b$\u0016\u001b\u0019\u001e",
    "! #\"%$\t\b  0 \f",
    "\u000f\u0018 \u0013\u001c",
    "\u0013 7 hook \b \u0018 \u0013\n",
    "# 2. For all labels \u0018 7- \u0016\u0005\u0004\u0007\u0006\t\b :\n",
    "# hole \b$\u0016\u001b\u001e",
    ") #\"%$\t\b  0 \f",
    "\u000f\u0018\u0019\u0013\u001c",
    "\u0013 7 hole \b  0 \u0013 +\n",
    "# hole \b \u0018 \u0013\n",
    "# 3. lzt \b$\u0016\u001b\u0019\u001e",
    "! #\"%$ \b  0 \f",
    "\u000f\u0018 \u0013\u001c",
    "\u0013 7 lzt \b  0 \u0013 % lzt \b \u0018 \u0013\n",
    "# 4. eq \b$\u0016\u001b\u0019\u001e",
    "! #\"%$ \b  0 \f",
    "\u000f\u0018\u0019\u0013\u001c",
    "\u0013 7 ' \b\u001a\u0006*) \b  0 \u0013 + \u0006*) \b \u0018\u0019\u0013\u0005+\n",
    "# \u001c",
    " hook \b  0 \u0013 7 hole \u001e",
    ") 9\"%$ \b \u0018 \u0013\u001b- \u0013\n",
    "# where ' stands for transitive closure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "40b9fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "483bac02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMRS(hook=['h2', 'x3'], hole={}, rels=[EPS(handle='h1', pred=Pred(name='cat', args=['x2'])), EPS(handle='h3', pred=Pred(name='every', args=['x3']))], hcons=set(), equalities=[('h1', 'h2'), ('x2', 'x3')])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMRS = namedtuple(\"RMRS\", [\"hook\", \"hole\", \"rels\", \"hcons\", \"equalities\"])\n",
    "\n",
    "Pred = namedtuple('Pred', ['name', 'args'])\n",
    "\n",
    "EPS = namedtuple('EPS', ['handle', 'pred'])\n",
    "\n",
    "def build_matrix(eq):\n",
    "    var = set()\n",
    "    for a, b in eq:\n",
    "        var |= {a, b}\n",
    "    \n",
    "    var = sorted(list(var))\n",
    "    \n",
    "    matrix = np.zeros((len(var), len(var)))\n",
    "\n",
    "    for i, a in enumerate(var):\n",
    "        for j, b in enumerate(var):\n",
    "            if (a, b) in eq or (b, a) in eq:\n",
    "                matrix[i,j] = 1\n",
    "    return matrix, var\n",
    "    \n",
    "def matrix_to_eq(mat, var):\n",
    "    for i, a in enumerate(var):\n",
    "        for j, b in enumerate(var):\n",
    "            if mat[i,j] == 1 and a != b and j > i:\n",
    "                yield (a, b)\n",
    "                \n",
    "    \n",
    "def tr(eq):\n",
    "    mat, var = build_matrix(eq)\n",
    "    \n",
    "    \n",
    "    mat = tr_helper(mat, var)\n",
    "    \n",
    "    return list(matrix_to_eq(mat, var))\n",
    "    \n",
    "def tr_helper(mat, var):\n",
    "    updated = False\n",
    "    for i in range(len(var)):\n",
    "        for j in range(len(var)):\n",
    "            if mat[i, j] == 1:\n",
    "                continue\n",
    "            else:\n",
    "                for k in range(len(var)):\n",
    "                    if mat[i, k] == 1 and mat[k, j] == 1:\n",
    "                        mat[i, j] = 1\n",
    "                        updated = True\n",
    "    if updated:\n",
    "        return tr_helper(mat, var)\n",
    "    else:\n",
    "        return mat\n",
    "    \n",
    "    \n",
    "eq = [('x1', 'x2'), ('x2', 'x3'), ('x4', 'x5')]\n",
    "mat, var = build_matrix(eq)\n",
    "assert(all([e in eq for e in matrix_to_eq(mat, var)]))\n",
    "eq2 = [('x1', 'x2'), ('x2', 'x3'), ('x4', 'x5'), ('x1', 'x3')]\n",
    "assert(all([e in eq2 for e in tr(eq)]))\n",
    "    \n",
    "    \n",
    "hnum = 0\n",
    "\n",
    "def get_hnum():\n",
    "    global hnum\n",
    "    h = f'h{hnum}'\n",
    "    hnum += 1\n",
    "    return h\n",
    "\n",
    "xnum = 0\n",
    "def get_x():\n",
    "    global xnum\n",
    "    x = f'x{xnum}'\n",
    "    xnum += 1\n",
    "    return x\n",
    "\n",
    "def op(a1, a2, label):\n",
    "    hook = a2.hook\n",
    "    \n",
    "    slots = {key: a1.hole.get(key, {}) | a2.hole.get(key, {}) for key in a1.hole.keys() | a2.hole.keys() if key != label}\n",
    "    \n",
    "    \n",
    "    new_rels = a1.rels + a2.rels \n",
    "    equalities = tr(a1.equalities | a2.equalities | {(a1.hook[0], a2.hole[label][0]), (a1.hook[1], a2.hole[label][1])})\n",
    "    hcons = a1.hcons | a2.hcons\n",
    "    \n",
    "    return RMRS(hook, slots, new_rels, hcons, equalities)\n",
    "\n",
    "\n",
    "cat = RMRS(['h1', 'x2'], {}, [EPS('h1', Pred('cat', ['x2']))], set(), set())\n",
    "every = RMRS(['h2', 'x3'], {'spec':['h2', 'x3']}, [EPS('h3', Pred('every', ['x3']))], set(), set())\n",
    "\n",
    "op(cat, every, 'spec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "af269d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h0'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hnum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c2b7230c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMRS(hook=['h3', 'x0'], hole={}, rels=[EPS(handle='h5', pred=Pred(name='dog', args=['x1'])), EPS(handle='h1', pred=Pred(name='every', args=['x0', 'h2', 'h4']))], hcons={('h1', 'h2')}, equalities=[('h1', 'h5'), ('x0', 'x1')])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = get_hnum()\n",
    "h2 = get_hnum()\n",
    "x = get_x()\n",
    "every = RMRS([get_hnum(), x], {'spec':[h, x]}, [EPS(h, Pred('every', [x, h2, get_hnum()]))], {(h, h2)}, set())\n",
    "h = get_hnum()\n",
    "x = get_x()\n",
    "dog = RMRS([h, x], {}, [EPS(h, Pred('dog', [x]))], set(), set())\n",
    "\n",
    "op(dog, every, 'spec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "702b0b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMRS(hook=['h8', 'x2'], hole={}, rels=[EPS(handle='h5', pred=Pred(name='dog', args=['x1'])), EPS(handle='h8', pred=Pred(name='white', args=['x2']))], hcons=set(), equalities=[('h5', 'h8'), ('x1', 'x2')])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = get_hnum()\n",
    "x = get_x()\n",
    "white = RMRS([h, x], {'mod':[h, x]}, [EPS(h, Pred('white', [x]))], set(), set())\n",
    "\n",
    "op(dog, white, 'mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "92d7a5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x2 x3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RMRS(hook=['x3'], hole={}, rels=[Pred(name='cat', args=['x2']), Pred(name='every', args=['x3'])], hcons=set(), equalities=[('x2', 'x3')])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op(cat, every, 'spec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cb06963f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 1., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0.]]),\n",
       " ['x1', 'x2', 'x3', 'x4', 'x5'])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq = [('x1', 'x2'), ('x3', 'x2'), ('x4', 'x5')]\n",
    "mat, var = build_matrix(eq)\n",
    "mat, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "471d2b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_helper(mat, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2a97339d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('x1', 'x2'), ('x1', 'x3'), ('x2', 'x3'), ('x4', 'x5')]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(matrix_to_eq(mat, var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "182c67a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('x1', 'x2'), ('x1', 'x3'), ('x2', 'x3'), ('x4', 'x5')]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "52daebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sents = nlp(u'a mug should be on it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5244491d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a mug\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "for chunk in sents.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "accf0034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 415 15267657372422890137\n",
      "mug 429 15794550382381185553\n",
      "should 405 16235386156175103506\n",
      "be 8206900633647566924 14200088355797579614\n",
      "on 443 1292078113972184607\n",
      "it 439 13656873538139661788\n"
     ]
    }
   ],
   "source": [
    "for t in sents:\n",
    "    print(t, t.dep, t.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6a4f79c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'a mug should be on it',\n",
       " 'ents': [],\n",
       " 'sents': [{'start': 0, 'end': 21}],\n",
       " 'tokens': [{'id': 0,\n",
       "   'start': 0,\n",
       "   'end': 1,\n",
       "   'pos': 'DET',\n",
       "   'tag': 'DT',\n",
       "   'dep': 'det',\n",
       "   'head': 1},\n",
       "  {'id': 1,\n",
       "   'start': 2,\n",
       "   'end': 5,\n",
       "   'pos': 'PROPN',\n",
       "   'tag': 'NNP',\n",
       "   'dep': 'nsubj',\n",
       "   'head': 3},\n",
       "  {'id': 2,\n",
       "   'start': 6,\n",
       "   'end': 12,\n",
       "   'pos': 'VERB',\n",
       "   'tag': 'MD',\n",
       "   'dep': 'aux',\n",
       "   'head': 3},\n",
       "  {'id': 3,\n",
       "   'start': 13,\n",
       "   'end': 15,\n",
       "   'pos': 'AUX',\n",
       "   'tag': 'VB',\n",
       "   'dep': 'ROOT',\n",
       "   'head': 3},\n",
       "  {'id': 4,\n",
       "   'start': 16,\n",
       "   'end': 18,\n",
       "   'pos': 'ADP',\n",
       "   'tag': 'IN',\n",
       "   'dep': 'prep',\n",
       "   'head': 3},\n",
       "  {'id': 5,\n",
       "   'start': 19,\n",
       "   'end': 21,\n",
       "   'pos': 'PRON',\n",
       "   'tag': 'PRP',\n",
       "   'dep': 'pobj',\n",
       "   'head': 4}]}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27cf405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dets(sents):\n",
    "    json_sent = sents.to_json()\n",
    "    for token in json_sent['tokens']:\n",
    "        if token['dep'] == 'det':\n",
    "            yield token\n",
    "            \n",
    "def get_dps(sents):\n",
    "    json_sent = sents.to_json()\n",
    "    dets = get_dets(sents)\n",
    "    for det in dets:\n",
    "        head = json_sent['tokens'][det['head']]\n",
    "        adj = json_sent['tokens'][det['id']+1:head['id']]\n",
    "        out = tuple([det] + adj + [head])\n",
    "        yield out\n",
    "    \n",
    "def get_root(sents):\n",
    "    json_sent = sents.to_json()\n",
    "    for token in json_sent['tokens']:\n",
    "        if token['dep'] == 'ROOT':\n",
    "            return token\n",
    "        \n",
    "def get_dp_word(dp, sents):\n",
    "    phrase = \" \".join([get_word(sents, t) for t in dp])\n",
    "    return phrase\n",
    "\n",
    "def get_word(sents, token):\n",
    "    return str(sents)[token['start']:token['end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c516d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import MutableSet\n",
    "\n",
    "class OrderedSet(MutableSet):\n",
    "\n",
    "    def __init__(self, iterable=None):\n",
    "        self.end = end = [] \n",
    "        end += [None, end, end]         # sentinel node for doubly linked list\n",
    "        self.map = {}                   # key --> [key, prev, next]\n",
    "        if iterable is not None:\n",
    "            self |= iterable\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.map)\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        return key in self.map\n",
    "\n",
    "    def add(self, key):\n",
    "        if key not in self.map:\n",
    "            end = self.end\n",
    "            curr = end[1]\n",
    "            curr[2] = end[1] = self.map[key] = [key, curr, end]\n",
    "\n",
    "    def discard(self, key):\n",
    "        if key in self.map:        \n",
    "            key, prev, next = self.map.pop(key)\n",
    "            prev[2] = next\n",
    "            next[1] = prev\n",
    "\n",
    "    def __iter__(self):\n",
    "        end = self.end\n",
    "        curr = end[2]\n",
    "        while curr is not end:\n",
    "            yield curr[0]\n",
    "            curr = curr[2]\n",
    "\n",
    "    def __reversed__(self):\n",
    "        end = self.end\n",
    "        curr = end[1]\n",
    "        while curr is not end:\n",
    "            yield curr[0]\n",
    "            curr = curr[1]\n",
    "\n",
    "    def pop(self, last=True):\n",
    "        if not self:\n",
    "            raise KeyError('set is empty')\n",
    "        key = self.end[1][0] if last else self.end[2][0]\n",
    "        self.discard(key)\n",
    "        return key\n",
    "\n",
    "    def __repr__(self):\n",
    "        if not self:\n",
    "            return '%s()' % (self.__class__.__name__,)\n",
    "        return '%s(%r)' % (self.__class__.__name__, list(self))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, OrderedSet):\n",
    "            return len(self) == len(other) and list(self) == list(other)\n",
    "        return set(self) == set(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bcdd7590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "class Grammar():\n",
    "    \n",
    "    def __init__(self, lexicon, rules, functions):\n",
    "        self.lexicon = lexicon\n",
    "        self.rules = rules\n",
    "        self.functions = functions\n",
    "        \n",
    "    def parse(self, sentence):\n",
    "        words = sentence.split()\n",
    "        \n",
    "        trace = defaultdict(list)\n",
    "        n = len(words) + 1\n",
    "        \n",
    "        for i in range(1, n):\n",
    "            word = words[i-1]\n",
    "            trace[(i-1, i)] = [[(syntax, semantics), word] for syntax, semantics, in self.lexicon[word]]\n",
    "        \n",
    "        for j in range(2, n):\n",
    "            for i in range(j-1, -1, -1):\n",
    "                for k in range(i+1, j):\n",
    "                    for c1, c2 in product(trace[(i, k)], trace[(k, j)]):\n",
    "                        \n",
    "                        for c3 in self.use_rules(c1[0], c2[0]):\n",
    "                            trace[(i, j)].append([c3, f\"{c1[1]} {c2[1]}\"])\n",
    "                            \n",
    "        return trace[(0, n-1)]\n",
    "                 \n",
    "        \n",
    "    def early(self, sentence):\n",
    "        words = sentence.split()\n",
    "        \n",
    "        S = [OrderedSet() for i in range(len(words)+1)]\n",
    "        \n",
    "        S[0].add((('<P>', ['.', '<S>']), 0))\n",
    "        \n",
    "        for i in range(0, len(words)):\n",
    "            for state, idx in S[i]:\n",
    "                if not finished(state):\n",
    "                    if is_non_terminal(next_element_of(state)):\n",
    "                        predictor(state, i, grammar, S)\n",
    "                    else:\n",
    "                        scanner(state, i, words, S)\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "    def use_rules(self, c1, c2):\n",
    "        for left, right, parent, app_order in self.rules:\n",
    "            if left == c1[0] and right == c2[0]:\n",
    "                sem = [c1[1], c2[1]]\n",
    "                yield (parent, f\"{sem[app_order[0]]}({sem[app_order[1]]})\")\n",
    "        \n",
    "    def sem(self, lf):\n",
    "        \"\"\"Interpret, as Python code, the root of a logical form\n",
    "        generated by this grammar.\"\"\"\n",
    "        # Import all of the user's functions into the namespace to\n",
    "        # help with the interpretation of the logical forms.\n",
    "        grammar = sys.modules[__name__]\n",
    "        for key, val in list(self.functions.items()):\n",
    "            setattr(grammar, key, val)        \n",
    "        return eval(lf[0][1]) # Interpret just the root node's semantics. \n",
    "        \n",
    "def finished(state):\n",
    "    return state[1][-1] == '.'\n",
    "        \n",
    "def next_element_of(state):\n",
    "    for i in range(len(state[1])):\n",
    "        if state[1][i] == '.':\n",
    "            return state[1][i+1]\n",
    "        \n",
    "def is_non_terminal(element):\n",
    "    return '<' in element and '>' in element\n",
    "\n",
    "def new_state(state):\n",
    "    p, r = state\n",
    "    r = copy.deepcopy(r)\n",
    "    r.insert(0, '.')\n",
    "\n",
    "def predictor(state, i, grammar, S):\n",
    "    B = next_element_of(state)\n",
    "    for rule in [(p, r) for p, r in grammar if p == B]:\n",
    "        \n",
    "        S[i+1].append((p, new_state(r)))\n",
    "\n",
    "def scanner(state, i, words):\n",
    "    a = next_element_of(state)\n",
    "    if a in \n",
    "        \n",
    "g = Grammar(gold_lexicon, rules, functions)\n",
    "# p = g.parse(\"minus two plus three\")\n",
    "# print(p)\n",
    "# for lf in p:\n",
    "#     print(g.sem(lf))\n",
    "\n",
    "print(finished(('<P>', ['<S>', '.'])))\n",
    "print(finished(('<P>', ['.', '<S>'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c5033245",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-4cc04ae11b01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "r = [1, 2]\n",
    "r.insert('a', 0)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fdc91104",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-104-143a9e8212dc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-104-143a9e8212dc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <P> ::= <S>      # the start rule\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<P> ::= <S>      # the start rule\n",
    "<S> ::= <S> \"+\" <M> | <M>\n",
    "<M> ::= <M> \"*\" <T> | <T>\n",
    "<T> ::= \"1\" | \"2\" | \"3\" | \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5e024b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "    ('<P>', ['<S>']),\n",
    "    ('<S>', ['<S>', '+', '<M>']),\n",
    "    ('<S>', ['M']),\n",
    "    ('<M>', ['<M>', '*', '<T>']),\n",
    "    ('<M>', ['<T>']),\n",
    "    ('<T>', ['1']),\n",
    "    ('<T>', ['2']),\n",
    "    ('<T>', ['3']),\n",
    "    ('<T>', ['4'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "726560a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_lexicon = {\n",
    "    'one':   [('N', '1')],\n",
    "    'two':   [('N', '2')],\n",
    "    'three': [('N', '3')],\n",
    "    'four':  [('N', '4')],\n",
    "    'five':  [('N', '5')],\n",
    "    'six':   [('N', '6')],\n",
    "    'seven': [('N', '7')],\n",
    "    'eight': [('N', '8')],\n",
    "    'nine':  [('N', '9')],\n",
    "    'plus':  [('R', 'add')],\n",
    "    'minus': [('R', 'subtract'), ('U', 'neg')],\n",
    "    'times': [('R', 'multiply')],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94939658",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "    ['B', 'N', 'N', (0,1)], \n",
    "    ['U', 'N', 'N', (0,1)], \n",
    "    ['N', 'R', 'B', (1,0)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45ebcb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = {\n",
    "    'neg': (lambda x : -x),\n",
    "    'add': (lambda x : (lambda y : x + y)),\n",
    "    'subtract': (lambda x : (lambda y : x - y)),\n",
    "    'multiply': (lambda x : (lambda y : x * y))\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f34ccc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a green cup\n",
      "the table\n"
     ]
    }
   ],
   "source": [
    "for t in get_dps(sents):\n",
    "    print(get_dp_word(t, sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2d08cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'There should be a green cup on the table',\n",
       " 'ents': [],\n",
       " 'sents': [{'start': 0, 'end': 40}],\n",
       " 'tokens': [{'id': 0,\n",
       "   'start': 0,\n",
       "   'end': 5,\n",
       "   'pos': 'PRON',\n",
       "   'tag': 'EX',\n",
       "   'dep': 'expl',\n",
       "   'head': 2},\n",
       "  {'id': 1,\n",
       "   'start': 6,\n",
       "   'end': 12,\n",
       "   'pos': 'VERB',\n",
       "   'tag': 'MD',\n",
       "   'dep': 'aux',\n",
       "   'head': 2},\n",
       "  {'id': 2,\n",
       "   'start': 13,\n",
       "   'end': 15,\n",
       "   'pos': 'AUX',\n",
       "   'tag': 'VB',\n",
       "   'dep': 'ROOT',\n",
       "   'head': 2},\n",
       "  {'id': 3,\n",
       "   'start': 16,\n",
       "   'end': 17,\n",
       "   'pos': 'DET',\n",
       "   'tag': 'DT',\n",
       "   'dep': 'det',\n",
       "   'head': 5},\n",
       "  {'id': 4,\n",
       "   'start': 18,\n",
       "   'end': 23,\n",
       "   'pos': 'ADJ',\n",
       "   'tag': 'JJ',\n",
       "   'dep': 'amod',\n",
       "   'head': 5},\n",
       "  {'id': 5,\n",
       "   'start': 24,\n",
       "   'end': 27,\n",
       "   'pos': 'NOUN',\n",
       "   'tag': 'NN',\n",
       "   'dep': 'attr',\n",
       "   'head': 2},\n",
       "  {'id': 6,\n",
       "   'start': 28,\n",
       "   'end': 30,\n",
       "   'pos': 'ADP',\n",
       "   'tag': 'IN',\n",
       "   'dep': 'prep',\n",
       "   'head': 5},\n",
       "  {'id': 7,\n",
       "   'start': 31,\n",
       "   'end': 34,\n",
       "   'pos': 'DET',\n",
       "   'tag': 'DT',\n",
       "   'dep': 'det',\n",
       "   'head': 8},\n",
       "  {'id': 8,\n",
       "   'start': 35,\n",
       "   'end': 40,\n",
       "   'pos': 'NOUN',\n",
       "   'tag': 'NN',\n",
       "   'dep': 'pobj',\n",
       "   'head': 6}]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e905f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = {''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec0fcd0-6bc0-4035-856f-ec5fcb29e49e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chart' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9aa2e74b4abb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCCGChartParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultRuleSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'chart' is not defined"
     ]
    }
   ],
   "source": [
    "parser = chart.CCGChartParser(lex, chart.DefaultRuleSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f517ac0-ad4b-466e-a8a6-d41d0176f92b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-91566c6a0147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you prefer that cake\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# doctest: +SKIP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mchart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintCCGDerivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parser' is not defined"
     ]
    }
   ],
   "source": [
    "for parse in parser.parse(\"you prefer that cake\".split()):  # doctest: +SKIP\n",
    "    chart.printCCGDerivation(parse)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a6c126a-7f6c-4916-b23d-552d80700d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I     should         give      you   the    cake\n",
      " NP  ((S\\NP)/VP)  ((VP/NP)/NP)  NP   (NP/N)   N\n",
      "                 ------------------->\n",
      "                       (VP/NP)\n",
      "                                    -------------->\n",
      "                                          NP\n",
      "                 --------------------------------->\n",
      "                                VP\n",
      "    ---------------------------------------------->\n",
      "                        (S\\NP)\n",
      "--------------------------------------------------<\n",
      "                        S\n"
     ]
    }
   ],
   "source": [
    "parser = chart.CCGChartParser(lex, chart.DefaultRuleSet)\n",
    "for parse in parser.parse(\"I should give you the cake\".split()):  # doctest: +SKIP\n",
    "    chart.printCCGDerivation(parse)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7664e11-5a80-4497-8952-5e7df194bfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.t.i.a.t.i.t.c.|\n",
      "|[-] . . . . . .| [0:1] 'there'\n",
      "|. [-] . . . . .| [1:2] 'is'\n",
      "|. . [-] . . . .| [2:3] 'a'\n",
      "|. . . [-] . . .| [3:4] 'table'\n",
      "|. . . . [-] . .| [4:5] 'in'\n",
      "|. . . . . [-] .| [5:6] 'the'\n",
      "|. . . . . . [-]| [6:7] 'centre'\n",
      "|[-> . . . . . .| [0:1] VP[NUM=?n] -> 'there' * BE[NUM=?n] {}\n",
      "|[-] . . . . . .| [0:1] THERE[] -> 'there' *\n",
      "|. [-] . . . . .| [1:2] BE[NUM='sg'] -> 'is' *\n",
      "|[---] . . . . .| [0:2] VP[NUM='sg'] -> 'there' BE[NUM='sg'] *\n",
      "|[---> . . . . .| [0:2] S[SEM=?np] -> VP[NUM=?n] * NPP[NUM=?n, SEM=?np] {?n: 'sg'}\n",
      "|. . [-] . . . .| [2:3] Det[NUM='sg', SEM=<\\P Q.(([x],[]) + P(x) + Q(x))>] -> 'a' *\n",
      "|. . [-> . . . .| [2:3] NP[NUM=?n, SEM=<?det(?np)>] -> Det[NUM=?n, SEM=?det] * N[NUM=?n, SEM=?np] {?det: <DrtLambdaExpression \\P Q.(([x],[]) + P(x) + Q(x))>, ?n: 'sg'}\n",
      "|. . . [-] . . .| [3:4] N[NUM='sg', SEM=<\\x.([],[Table(x)])>] -> 'table' *\n",
      "|. . [---] . . .| [2:4] NP[NUM='sg', SEM=<\\Q.(([x],[Table(x)]) + Q(x))>] -> Det[NUM='sg', SEM=<\\P Q.(([x],[]) + P(x) + Q(x))>] N[NUM='sg', SEM=<\\x.([],[Table(x)])>] *\n",
      "|. . [---> . . .| [2:4] NPP[NUM=?n, SEM=<?np(?pp)>] -> NP[NUM=?n, SEM=?np] * PP[SEM=?pp] {?n: 'sg', ?np: <DrtLambdaExpression \\Q.(([x],[Table(x)]) + Q(x))>}\n",
      "|. . . . [-] . .| [4:5] P[SEM=<\\y x.([],[on(x,y)])>] -> 'in' *\n",
      "|. . . . [-> . .| [4:5] PP[SEM=<?p(?loc)>] -> P[SEM=?p] * LOC[SEM=?loc] {?p: <DrtLambdaExpression \\y x.([],[on(x,y)])>}\n",
      "|. . . . . [-> .| [5:6] LOC[SEM=<vector(0,0,0)>] -> 'the' * 'centre' {}\n",
      "|. . . . . [-] .| [5:6] The[] -> 'the' *\n",
      "|. . . . . [---]| [5:7] LOC[SEM=<vector(0,0,0)>] -> 'the' 'centre' *\n",
      "|. . . . [-----]| [4:7] PP[SEM=<\\x.([],[on(x,vector(0,0,0))])>] -> P[SEM=<\\y x.([],[on(x,y)])>] LOC[SEM=<vector(0,0,0)>] *\n",
      "|. . [---------]| [2:7] NPP[NUM='sg', SEM=<([x],[Table(x), on(x,vector(0,0,0))])>] -> NP[NUM='sg', SEM=<\\Q.(([x],[Table(x)]) + Q(x))>] PP[SEM=<\\x.([],[on(x,vector(0,0,0))])>] *\n",
      "|[=============]| [0:7] S[SEM=<([x],[Table(x), on(x,vector(0,0,0))])>] -> VP[NUM='sg'] NPP[NUM='sg', SEM=<([x],[Table(x), on(x,vector(0,0,0))])>] *\n",
      "([x],[Table(x), on(x,vector(0,0,0))])\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse import load_parser\n",
    "from nltk.sem.drt import DrtParser\n",
    "parser = load_parser('grammar.fcfg', trace=1, logic_parser=DrtParser())\n",
    "for tree in parser.parse('there is a table in the centre'.split()):\n",
    "     print(tree.label()['SEM'].simplify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d2145ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = parser.grammar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66a37835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Grammar with 17 productions>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "424591bc-4fff-49bb-850c-fd3ec47903ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: \"'The', '1.8m', 'wide', 'and', '0.8m', 'long'\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c439d548bb17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The table is 1.8m wide and 0.8m long'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SEM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/probrobnlp/lib/python3.9/site-packages/nltk/parse/chart.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokens, tree_class)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchart_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/probrobnlp/lib/python3.9/site-packages/nltk/parse/chart.py\u001b[0m in \u001b[0;36mchart_parse\u001b[0;34m(self, tokens, trace)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_coverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m         \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chart_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mgrammar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/probrobnlp/lib/python3.9/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mcheck_coverage\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    676\u001b[0m                 \u001b[0;34m\"Grammar does not cover some of the \"\u001b[0m \u001b[0;34m\"input words: %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Grammar does not cover some of the input words: \"'The', '1.8m', 'wide', 'and', '0.8m', 'long'\"."
     ]
    }
   ],
   "source": [
    "for tree in parser.parse('The table is 1.8m wide and 0.8m long'.split()):\n",
    "     print(tree.label()['SEM'].simplify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "511bc78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProbRobNLP.probrob import *\n",
    "from nltk.sem.drt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "095bb722-f53f-4f7f-98d0-27322c04cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class WorldModel():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "class InterpretationSystem():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dialogue_history = []\n",
    "        self.dialogue_referents = []\n",
    "        self.parser = load_parser('grammar.fcfg', trace=0, logic_parser=DrtParser())\n",
    "        \n",
    "        \n",
    "    def read_sentence(self, sentence: str):\n",
    "        for tree in self.parser.parse(sentence.split()):\n",
    "             sem = tree.label()['SEM'].simplify()\n",
    "        \n",
    "        return sem\n",
    "    \n",
    "    def read_DRS(self, drs: DRS):\n",
    "        \n",
    "        refs = [r.name for r in drs.refs]\n",
    "        preds = [parse_cond(cond) for cond in drs.conds]\n",
    "        return DRSState(preds, refs)\n",
    "            \n",
    "\n",
    "            \n",
    "                \n",
    "def parse_cond(cond):\n",
    "    if isinstance(cond, DrtApplicationExpression):\n",
    "        pred = cond.pred.variable.name\n",
    "#         print(pred)\n",
    "        args = [parse_cond(x) for x in cond.args]\n",
    "#         print(args)\n",
    "\n",
    "        return Predicate(pred, args)\n",
    "\n",
    "#         if pred in ['table', 'cup']:\n",
    "            \n",
    "#             obj = (pred, args)\n",
    "#             return obj\n",
    "            \n",
    "#         elif pred in ['vector']:\n",
    "#             vector = Vector3D(*args)\n",
    "#             return vector\n",
    "#         elif pred in ['on']:\n",
    "#             return (pred, args)\n",
    "        \n",
    "    if isinstance(cond, DrtIndividualVariableExpression) or isinstance(cond, DrtConstantExpression):\n",
    "        return cond.variable.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e9fba70-d0b3-4af6-9da5-a7dcf60fc228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Predicate(object):\n",
    "\n",
    "    def __init__(self, name, args, op=None):\n",
    "        self.name = name\n",
    "        self.args = args\n",
    "        self.valency = not(op == 'not')\n",
    "        self.op = op\n",
    "\n",
    "    def negate(self):\n",
    "        op = 'not' if self.valency is True else None\n",
    "        return Predicate(self.name, self.args, op)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}({','.join(map(str, self.args))})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name and all([arg1 == arg2 for arg1, arg2 in zip(self.args, other.args)]) and len(self.args) == len(other.args)\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not(self.__eq__(other))\n",
    "\n",
    "    def to_dexpr(self):\n",
    "        \n",
    "        return DrtExpression.fromstring(self.__str__())\n",
    "        \n",
    "    def toPRS(self):\n",
    "        if self.name == \"on\":\n",
    "            arg1 = get_prs(self.args[1])\n",
    "            return OnConstraint(arg1)\n",
    "        elif self.name == \"vector\":\n",
    "            return Vector3D(*map(get_prs, self.args))\n",
    "        \n",
    "        \n",
    "def get_prs(predicate):\n",
    "    if isinstance(predicate, Predicate):\n",
    "        return predicate.toPRS()\n",
    "    else:\n",
    "        return predicate\n",
    "    \n",
    "class DRSState(object):\n",
    "    def __init__(self, predicates, referents):\n",
    "        self.referents = referents\n",
    "        self.predicates = predicates\n",
    "\n",
    "    def get_predicates(self, arg):\n",
    "        return [pred for pred in self.predicates if arg in pred.args]\n",
    "    \n",
    "    def get_first_place_predicates(self, arg):\n",
    "        return [pred for pred in self.predicates if arg == pred.args[0]]\n",
    "\n",
    "    def _predicate_holds(self, predicate):\n",
    "        return predicate in self.predicates\n",
    "\n",
    "    def predicate_holds(self, predicate_name, args):\n",
    "        predicate = Predicate(predicate_name, args)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        for predicate in self.predicates:\n",
    "            if predicate not in other.predicates:\n",
    "                return False\n",
    "        for predicate in other.predicates:\n",
    "            if predicate not in self.predicates:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def asDRS(self):\n",
    "        dexpr = [pred.to_dexpr() for pred in self.predicates]\n",
    "        return DRS(self.referents, dexpr)\n",
    "    \n",
    "    def print(self):\n",
    "        drs = self.asDRS()\n",
    "        drs.pretty_print()\n",
    "\n",
    "        \n",
    "    def toPRS(self):\n",
    "        for referent in self.referents:\n",
    "            type_ = None\n",
    "            constraints = []\n",
    "            for predicate in self.get_first_place_predicates(referent):\n",
    "                if predicate.name in ['Table', 'Cup']:\n",
    "                    type_ = predicate.name\n",
    "                else:\n",
    "                    constraints.append(predicate.toPRS())\n",
    "            print(Entity(type_, referent, constraints))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb4c3969-e53a-416e-bf00-593e5cc96c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [Predicate('Table', ['x']), Predicate('on', ['x', Predicate('vector', [0, 0, 0])])]\n",
    "d = DRSState(preds, ['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85848b0d-3114-4705-a8ec-20b855a05fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Table on Vector3D(0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "d.toPRS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6973034b-e5f6-4f4d-948f-339d4087cb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0d536b8-844d-4de2-b1f6-f5cc61646f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Table on Vector3D(0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "s = InterpretationSystem()\n",
    "sem = s.read_sentence(\"there is a table on the centre\")\n",
    "s.read_DRS(sem).toPRS()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "61ac89b8-25dd-448d-9e8e-80d2486d5839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _____________________ \n",
      "| x                   |\n",
      "|---------------------|\n",
      "| table(x)            |\n",
      "| on(x,vector(0,0,0)) |\n",
      "|_____________________|\n"
     ]
    }
   ],
   "source": [
    "sem.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "44e80a73-251c-4ba1-9f73-c5ea31c8b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem.predicates()\n",
    "fol = sem.fol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "965f7d3c-c528-4f6e-90cb-1054360604c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem.refs[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2ad3f306-373a-4937-b753-9109956b1f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.args[1].args[0].variable.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc29a389-98bd-4b13-8bda-a2e195938b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fol_sem = sem.fol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3255e194-4383-42aa-9d1f-68232d7d5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "and_expr = fol_sem.term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1bbb14d-2d7f-4860-8eb0-efd581620295",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = and_expr.first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce89bf74-a7c1-4eec-8fa0-84b557d8af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s= and_expr.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9f40c6b-4779-44ee-8a16-f6aa88b7e53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DrtIndividualVariableExpression x>, <ApplicationExpression vector(0,0,0)>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59b8e2-f197-4bf9-acb8-9a527da9a6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
