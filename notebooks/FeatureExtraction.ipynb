{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "713643c0-be46-4481-a0dc-e0e1c75a00e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'a mug should be on it',\n",
       " 'ents': [],\n",
       " 'sents': [{'start': 0, 'end': 21}],\n",
       " 'tokens': [{'id': 0,\n",
       "   'start': 0,\n",
       "   'end': 1,\n",
       "   'pos': 'DET',\n",
       "   'tag': 'DT',\n",
       "   'dep': 'det',\n",
       "   'head': 1},\n",
       "  {'id': 1,\n",
       "   'start': 2,\n",
       "   'end': 5,\n",
       "   'pos': 'PROPN',\n",
       "   'tag': 'NNP',\n",
       "   'dep': 'nsubj',\n",
       "   'head': 3},\n",
       "  {'id': 2,\n",
       "   'start': 6,\n",
       "   'end': 12,\n",
       "   'pos': 'VERB',\n",
       "   'tag': 'MD',\n",
       "   'dep': 'aux',\n",
       "   'head': 3},\n",
       "  {'id': 3,\n",
       "   'start': 13,\n",
       "   'end': 15,\n",
       "   'pos': 'AUX',\n",
       "   'tag': 'VB',\n",
       "   'dep': 'ROOT',\n",
       "   'head': 3},\n",
       "  {'id': 4,\n",
       "   'start': 16,\n",
       "   'end': 18,\n",
       "   'pos': 'ADP',\n",
       "   'tag': 'IN',\n",
       "   'dep': 'prep',\n",
       "   'head': 3},\n",
       "  {'id': 5,\n",
       "   'start': 19,\n",
       "   'end': 21,\n",
       "   'pos': 'PRON',\n",
       "   'tag': 'PRP',\n",
       "   'dep': 'pobj',\n",
       "   'head': 4}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sents = nlp(u'a mug should be on it')\n",
    "\n",
    "sents.to_json()\n",
    "\n",
    "# def get_words_and_tags(sentence):\n",
    "#     nlp = spacy.load(\"en_core_web_sm\")\n",
    "#     sents = nlp(sentence)\n",
    "    \n",
    "#     for token in sents['tokens']:\n",
    "#         word = sents[token['start']:token['end']]\n",
    "#         tag = token['tag']\n",
    "        \n",
    "#         yield (word, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14822e62-3757-424c-9ae1-ad2956bfdabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'a green mug should be on the tray',\n",
       " 'ents': [],\n",
       " 'sents': [{'start': 0, 'end': 33}],\n",
       " 'tokens': [{'id': 0,\n",
       "   'start': 0,\n",
       "   'end': 1,\n",
       "   'pos': 'DET',\n",
       "   'tag': 'DT',\n",
       "   'dep': 'det',\n",
       "   'head': 2},\n",
       "  {'id': 1,\n",
       "   'start': 2,\n",
       "   'end': 7,\n",
       "   'pos': 'ADJ',\n",
       "   'tag': 'JJ',\n",
       "   'dep': 'amod',\n",
       "   'head': 2},\n",
       "  {'id': 2,\n",
       "   'start': 8,\n",
       "   'end': 11,\n",
       "   'pos': 'NOUN',\n",
       "   'tag': 'NN',\n",
       "   'dep': 'nsubj',\n",
       "   'head': 4},\n",
       "  {'id': 3,\n",
       "   'start': 12,\n",
       "   'end': 18,\n",
       "   'pos': 'VERB',\n",
       "   'tag': 'MD',\n",
       "   'dep': 'aux',\n",
       "   'head': 4},\n",
       "  {'id': 4,\n",
       "   'start': 19,\n",
       "   'end': 21,\n",
       "   'pos': 'AUX',\n",
       "   'tag': 'VB',\n",
       "   'dep': 'ROOT',\n",
       "   'head': 4},\n",
       "  {'id': 5,\n",
       "   'start': 22,\n",
       "   'end': 24,\n",
       "   'pos': 'ADP',\n",
       "   'tag': 'IN',\n",
       "   'dep': 'prep',\n",
       "   'head': 4},\n",
       "  {'id': 6,\n",
       "   'start': 25,\n",
       "   'end': 28,\n",
       "   'pos': 'DET',\n",
       "   'tag': 'DT',\n",
       "   'dep': 'det',\n",
       "   'head': 7},\n",
       "  {'id': 7,\n",
       "   'start': 29,\n",
       "   'end': 33,\n",
       "   'pos': 'NOUN',\n",
       "   'tag': 'NN',\n",
       "   'dep': 'pobj',\n",
       "   'head': 5}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = nlp(u'a green mug should be on the tray')\n",
    "\n",
    "sents.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17bbddf6-9f36-4c86-b081-feb615c8c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_and_tags(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    sents = nlp(sentence).to_json()\n",
    "    \n",
    "    # print(sents['tokens'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, token in enumerate(sents['tokens']):\n",
    "        word = sentence[token['start']:token['end']]\n",
    "        tag = token['tag']\n",
    "        dep = token['dep']\n",
    "        pos = token['pos']\n",
    "        head = token['head']\n",
    "        yield {'id':i, 'word':word, 'tag':tag, 'dep':dep, 'pos':pos, 'head':head}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f82f5f17-0fdf-4cf2-aa4f-4ce37249af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"An Acura Integra is parked in the lot\",\n",
    "             \"There is an Acura Integra parked in the lot.\",\n",
    "             \"John parked an Acura Integra in the lot.\", \n",
    "             \"John gave his Acura Integra a bath\",\n",
    "             \"Inside his Acura Integra, John showed Susan his new CD player\",\n",
    "             \"He liked it a lot\",\n",
    "            \"She generally gave herself very good advice\",\n",
    "            \"they ate three apples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e132a3ad-b167-4451-b5d2-6271428ae0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'word': 'An', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2}\n",
      "{'id': 1, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 2}\n",
      "{'id': 2, 'word': 'Integra', 'tag': 'NNP', 'dep': 'nsubjpass', 'pos': 'PROPN', 'head': 4}\n",
      "{'id': 3, 'word': 'is', 'tag': 'VBZ', 'dep': 'auxpass', 'pos': 'AUX', 'head': 4}\n",
      "{'id': 4, 'word': 'parked', 'tag': 'VBN', 'dep': 'ROOT', 'pos': 'VERB', 'head': 4}\n",
      "{'id': 5, 'word': 'in', 'tag': 'IN', 'dep': 'prep', 'pos': 'ADP', 'head': 4}\n",
      "{'id': 6, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 7}\n",
      "{'id': 7, 'word': 'lot', 'tag': 'NN', 'dep': 'pobj', 'pos': 'NOUN', 'head': 5}\n",
      "\n",
      "{'id': 0, 'word': 'There', 'tag': 'EX', 'dep': 'expl', 'pos': 'PRON', 'head': 1}\n",
      "{'id': 1, 'word': 'is', 'tag': 'VBZ', 'dep': 'ROOT', 'pos': 'AUX', 'head': 1}\n",
      "{'id': 2, 'word': 'an', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 4}\n",
      "{'id': 3, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 4}\n",
      "{'id': 4, 'word': 'Integra', 'tag': 'NNPS', 'dep': 'attr', 'pos': 'PROPN', 'head': 1}\n",
      "{'id': 5, 'word': 'parked', 'tag': 'VBN', 'dep': 'acl', 'pos': 'VERB', 'head': 4}\n",
      "{'id': 6, 'word': 'in', 'tag': 'IN', 'dep': 'prep', 'pos': 'ADP', 'head': 5}\n",
      "{'id': 7, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 8}\n",
      "{'id': 8, 'word': 'lot', 'tag': 'NN', 'dep': 'pobj', 'pos': 'NOUN', 'head': 6}\n",
      "{'id': 9, 'word': '.', 'tag': '.', 'dep': 'punct', 'pos': 'PUNCT', 'head': 1}\n",
      "\n",
      "{'id': 0, 'word': 'John', 'tag': 'NNP', 'dep': 'nsubj', 'pos': 'PROPN', 'head': 1}\n",
      "{'id': 1, 'word': 'parked', 'tag': 'VBD', 'dep': 'ROOT', 'pos': 'VERB', 'head': 1}\n",
      "{'id': 2, 'word': 'an', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 4}\n",
      "{'id': 3, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 4}\n",
      "{'id': 4, 'word': 'Integra', 'tag': 'NNP', 'dep': 'dobj', 'pos': 'PROPN', 'head': 1}\n",
      "{'id': 5, 'word': 'in', 'tag': 'IN', 'dep': 'prep', 'pos': 'ADP', 'head': 1}\n",
      "{'id': 6, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 7}\n",
      "{'id': 7, 'word': 'lot', 'tag': 'NN', 'dep': 'pobj', 'pos': 'NOUN', 'head': 5}\n",
      "{'id': 8, 'word': '.', 'tag': '.', 'dep': 'punct', 'pos': 'PUNCT', 'head': 1}\n",
      "\n",
      "{'id': 0, 'word': 'John', 'tag': 'NNP', 'dep': 'nsubj', 'pos': 'PROPN', 'head': 1}\n",
      "{'id': 1, 'word': 'gave', 'tag': 'VBD', 'dep': 'ROOT', 'pos': 'VERB', 'head': 1}\n",
      "{'id': 2, 'word': 'his', 'tag': 'PRP$', 'dep': 'poss', 'pos': 'DET', 'head': 4}\n",
      "{'id': 3, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 4}\n",
      "{'id': 4, 'word': 'Integra', 'tag': 'NNP', 'dep': 'dative', 'pos': 'PROPN', 'head': 1}\n",
      "{'id': 5, 'word': 'a', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 6}\n",
      "{'id': 6, 'word': 'bath', 'tag': 'NN', 'dep': 'dobj', 'pos': 'NOUN', 'head': 1}\n",
      "\n",
      "{'id': 0, 'word': 'Inside', 'tag': 'IN', 'dep': 'prep', 'pos': 'ADP', 'head': 6}\n",
      "{'id': 1, 'word': 'his', 'tag': 'PRP$', 'dep': 'poss', 'pos': 'DET', 'head': 3}\n",
      "{'id': 2, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 3}\n",
      "{'id': 3, 'word': 'Integra', 'tag': 'NNP', 'dep': 'pobj', 'pos': 'PROPN', 'head': 0}\n",
      "{'id': 4, 'word': ',', 'tag': ',', 'dep': 'punct', 'pos': 'PUNCT', 'head': 6}\n",
      "{'id': 5, 'word': 'John', 'tag': 'NNP', 'dep': 'nsubj', 'pos': 'PROPN', 'head': 6}\n",
      "{'id': 6, 'word': 'showed', 'tag': 'VBD', 'dep': 'ROOT', 'pos': 'VERB', 'head': 6}\n",
      "{'id': 7, 'word': 'Susan', 'tag': 'NNP', 'dep': 'dative', 'pos': 'PROPN', 'head': 6}\n",
      "{'id': 8, 'word': 'his', 'tag': 'PRP$', 'dep': 'poss', 'pos': 'DET', 'head': 11}\n",
      "{'id': 9, 'word': 'new', 'tag': 'JJ', 'dep': 'amod', 'pos': 'ADJ', 'head': 11}\n",
      "{'id': 10, 'word': 'CD', 'tag': 'NN', 'dep': 'compound', 'pos': 'NOUN', 'head': 11}\n",
      "{'id': 11, 'word': 'player', 'tag': 'NN', 'dep': 'dobj', 'pos': 'NOUN', 'head': 6}\n",
      "\n",
      "{'id': 0, 'word': 'He', 'tag': 'PRP', 'dep': 'nsubj', 'pos': 'PRON', 'head': 1}\n",
      "{'id': 1, 'word': 'liked', 'tag': 'VBD', 'dep': 'ROOT', 'pos': 'VERB', 'head': 1}\n",
      "{'id': 2, 'word': 'it', 'tag': 'PRP', 'dep': 'dobj', 'pos': 'PRON', 'head': 1}\n",
      "{'id': 3, 'word': 'a', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 4}\n",
      "{'id': 4, 'word': 'lot', 'tag': 'NN', 'dep': 'npadvmod', 'pos': 'NOUN', 'head': 1}\n",
      "\n",
      "{'id': 0, 'word': 'She', 'tag': 'PRP', 'dep': 'nsubj', 'pos': 'PRON', 'head': 2}\n",
      "{'id': 1, 'word': 'generally', 'tag': 'RB', 'dep': 'advmod', 'pos': 'ADV', 'head': 2}\n",
      "{'id': 2, 'word': 'gave', 'tag': 'VBD', 'dep': 'ROOT', 'pos': 'VERB', 'head': 2}\n",
      "{'id': 3, 'word': 'herself', 'tag': 'PRP', 'dep': 'dative', 'pos': 'PRON', 'head': 2}\n",
      "{'id': 4, 'word': 'very', 'tag': 'RB', 'dep': 'advmod', 'pos': 'ADV', 'head': 5}\n",
      "{'id': 5, 'word': 'good', 'tag': 'JJ', 'dep': 'amod', 'pos': 'ADJ', 'head': 6}\n",
      "{'id': 6, 'word': 'advice', 'tag': 'NN', 'dep': 'dobj', 'pos': 'NOUN', 'head': 2}\n",
      "\n",
      "{'id': 0, 'word': 'they', 'tag': 'PRP', 'dep': 'nsubj', 'pos': 'PRON', 'head': 1}\n",
      "{'id': 1, 'word': 'ate', 'tag': 'VBD', 'dep': 'ROOT', 'pos': 'VERB', 'head': 1}\n",
      "{'id': 2, 'word': 'three', 'tag': 'CD', 'dep': 'nummod', 'pos': 'NUM', 'head': 3}\n",
      "{'id': 3, 'word': 'apples', 'tag': 'NNS', 'dep': 'dobj', 'pos': 'NOUN', 'head': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    for line in get_words_and_tags(sentence):\n",
    "        print(line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13cd3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d522dc40-af34-48d3-a224-16fa270ca467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_referents(sentence):\n",
    "    \n",
    "    sentence = list(get_words_and_tags(sentence))\n",
    "    for word in sentence:\n",
    "        out = []\n",
    "        if 'obj' in word['dep'] or 'subj' in word['dep'] or 'dative' in word['dep'] or 'attr' in word['dep']:\n",
    "\n",
    "            for w in sentence:\n",
    "                if w['head'] == word['id'] and w['dep'] != 'acl':\n",
    "                    out.append(w)\n",
    "            out.append(word)\n",
    "            yield out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a340c33a-c620-4050-8a3b-0fe4ad44a2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an Acura Integra', 'the lot']\n",
      "['John', 'an Acura Integra', 'the lot']\n",
      "['John', 'his Acura Integra', 'a bath']\n",
      "['his Acura Integra', 'John', 'Susan', 'his new CD player']\n"
     ]
    }
   ],
   "source": [
    "a = list(map(list_to_string, get_potential_referents(sentences[0])))\n",
    "assert('An Acura Integra' in a)\n",
    "assert('the lot' in a)\n",
    "\n",
    "a = list(map(list_to_string, get_potential_referents(sentences[1])))\n",
    "# assert('an Acura Integra' in a)\n",
    "# assert('the lot' in a)\n",
    "\n",
    "print(a)\n",
    "\n",
    "a = list(map(list_to_string, get_potential_referents(sentences[2])))\n",
    "\n",
    "print(a)\n",
    "\n",
    "a = list(map(list_to_string, get_potential_referents(sentences[3])))\n",
    "\n",
    "print(a)\n",
    "\n",
    "a = list(map(list_to_string, get_potential_referents(sentences[4])))\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c74752bc-7ec0-48ed-9ccd-e5a7a97bef28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Acura Integra\n",
      "the lot\n"
     ]
    }
   ],
   "source": [
    "for word in get_potential_referents(sentences[0]):\n",
    "    print(list_to_string(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92c883fa-9547-41b9-bc64-962645f28b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(word_list):\n",
    "    return ' '.join([w['word'] for w in word_list])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96c55282-5800-4159-b1da-f2b968dc030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_string_match(entity1, entity2):\n",
    "    \n",
    "    return list_to_string(entity1).lower() == list_to_string(entity2).lower()\n",
    "\n",
    "s1 = [{'id': 0, 'word': 'An', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2},\n",
    "{'id': 1, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 2},\n",
    "{'id': 2, 'word': 'Integra', 'tag': 'NNP', 'dep': 'nsubjpass', 'pos': 'PROPN', 'head': 4}]\n",
    "\n",
    "s2 =[{'id': 3, 'word': 'an', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 5},\n",
    "{'id': 4, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 5},\n",
    "{'id': 5, 'word': 'Integra', 'tag': 'NNP', 'dep': 'nsubjpass', 'pos': 'PROPN', 'head': 2}]\n",
    "\n",
    "s3 = [{'id': 0, 'word': 'The', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2},\n",
    "{'id': 1, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 2},\n",
    "{'id': 2, 'word': 'Integra', 'tag': 'NNP', 'dep': 'nsubjpass', 'pos': 'PROPN', 'head': 4}]\n",
    "\n",
    "assert(exact_string_match(s1, s2))\n",
    "assert(not exact_string_match(s2, s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52e216d3-443e-4190-92fd-6ebf21c8cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_string_match(antecedent, target):\n",
    "    \n",
    "    return list_to_string(target).lower() in list_to_string(antecedent).lower()\n",
    "\n",
    "s1 = [{'id': 0, 'word': 'An', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2},\n",
    "{'id': 1, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 2},\n",
    "{'id': 2, 'word': 'Integra', 'tag': 'NNP', 'dep': 'nsubjpass', 'pos': 'PROPN', 'head': 4}]\n",
    "\n",
    "s2 =[{'id': 3, 'word': 'an', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 5},\n",
    "{'id': 4, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 5},\n",
    "{'id': 5, 'word': 'Integra', 'tag': 'NNP', 'dep': 'nsubjpass', 'pos': 'PROPN', 'head': 2}]\n",
    "\n",
    "s3 = [{'id': 0, 'word': 'The', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2},\n",
    "{'id': 1, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 2},\n",
    "{'id': 2, 'word': 'Integra', 'tag': 'NNP', 'dep': 'nsubjpass', 'pos': 'PROPN', 'head': 4}]\n",
    "\n",
    "assert(sub_string_match(s1, s2))\n",
    "assert(not exact_string_match(s2, s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8359ee4a-fcec-4fdd-8881-249c1ae7fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_overlap_match(antecedent, target):\n",
    "    antecedent = list_to_string(antecedent).lower()\n",
    "\n",
    "    for word in target:\n",
    "        if word['word'].lower() in antecedent:\n",
    "\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "s1 = [{'id': 0, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2},\n",
    "{'id': 1, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 2},\n",
    "{'id': 2, 'word': 'Integra', 'tag': 'NNP', 'dep': 'nsubjpass', 'pos': 'PROPN', 'head': 4}]\n",
    "\n",
    "s2 =[{'id': 3, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 5},\n",
    "     {'id': 4, 'word': 'big', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 5},\n",
    "{'id': 5, 'word': 'Acura', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 5},\n",
    "{'id': 6, 'word': 'Integra', 'tag': 'NNP', 'dep': 'nsubjpass', 'pos': 'PROPN', 'head': 2}]\n",
    "\n",
    "s3 = [{'id': 0, 'word': 'The', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2},\n",
    "{'id': 1, 'word': 'Acuras', 'tag': 'NNP', 'dep': 'compound', 'pos': 'PROPN', 'head': 2},\n",
    "{'id': 2, 'word': 'Integra', 'tag': 'NNP', 'dep': 'nsubjpass', 'pos': 'PROPN', 'head': 4}]\n",
    "\n",
    "# assert(sub_string_match(s2, s1))\n",
    "# assert(not sub_string_match(s2, s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a9fcbd-1130-48a8-980d-d351ce0bb401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "919986eb-dfa2-4ea1-8ebd-ce8bba9949e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ffb709e-378c-450b-bb73-67fe9dc9cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(antecedent, target, threshold=2):\n",
    "    return levenshtein(antecedent, target) <= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3f0a65d-c6d4-4012-a3f8-fa4a4e370e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(edit_distance('hello', 'hillo'))\n",
    "assert(edit_distance('hello', 'hilo'))\n",
    "assert(not edit_distance('hello', 'bilo'))\n",
    "assert(edit_distance('hello', 'bilo', threshold=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a97b770e-5743-46ce-8bf3-c812e574ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "definites = [\"his\", \"her\", \"my\", \"your\", \"its\", \"our\", \"their\", \"this\", \"these\", \"that\", \"those\", \"the\"]\n",
    "\n",
    "def definiteness(antecedent):\n",
    "    words = [a['word'].lower() for a in antecedent]\n",
    "    return any([definite in words for definite in definites])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c740c9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An Acura Integra is parked in the lot',\n",
       " 'There is an Acura Integra parked in the lot.',\n",
       " 'John parked an Acura Integra in the lot.',\n",
       " 'John gave his Acura Integra a bath',\n",
       " 'Inside his Acura Integra, John showed Susan his new CD player',\n",
       " 'He liked it a lot']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70bce0ba-1622-40af-8fb0-ca4eeb7e6f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for sentence in sentences:\n",
    "    test += list(get_potential_referents(sentence))\n",
    "\n",
    "# test = list(get_potential_referents(sentences[0]))\n",
    "# test += get_potential_referents(sentences[1])\n",
    "# test += get_potential_referents(sentences[2])\n",
    "# test += get_potential_referents(sentences[3])\n",
    "# test += get_potential_referents(sentences[4])\n",
    "# test += get_potential_referents(sentences[5])\n",
    "# # assert('an Acura Integra' in a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dd024b95-ae56-4607-a022-fe98de8202de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Acura Integra False\n",
      "the lot True\n",
      "an Acura Integra False\n",
      "the lot True\n",
      "John False\n",
      "an Acura Integra False\n",
      "the lot True\n",
      "John False\n",
      "his Acura Integra True\n",
      "a bath False\n",
      "his Acura Integra True\n",
      "John False\n",
      "Susan False\n",
      "his new CD player True\n",
      "He False\n",
      "it False\n",
      "She False\n",
      "herself False\n",
      "good advice False\n",
      "they False\n",
      "three apples False\n"
     ]
    }
   ],
   "source": [
    "for antecedent in test:\n",
    "    print(list_to_string(antecedent), definiteness(antecedent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c062b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75814708-dcd4-494c-892a-a229e601ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proper_noun(entity):\n",
    "    return all([word['pos'] == \"PROPN\" for word in entity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c900bbe8-b3f2-4eb0-a667-456a0145664a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Acura Integra False\n",
      "the lot False\n",
      "an Acura Integra False\n",
      "the lot False\n",
      "John True\n",
      "an Acura Integra False\n",
      "the lot False\n",
      "John True\n",
      "his Acura Integra False\n",
      "a bath False\n",
      "his Acura Integra False\n",
      "John True\n",
      "Susan True\n",
      "his new CD player False\n",
      "He False\n",
      "it False\n"
     ]
    }
   ],
   "source": [
    "for antecedent in test:\n",
    "    print(list_to_string(antecedent), proper_noun(antecedent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "209f3e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Acura Integra False\n",
      "the lot False\n",
      "an Acura Integra False\n",
      "the lot False\n",
      "John False\n",
      "an Acura Integra False\n",
      "the lot False\n",
      "John False\n",
      "his Acura Integra False\n",
      "a bath False\n",
      "his Acura Integra False\n",
      "John False\n",
      "Susan False\n",
      "his new CD player False\n",
      "He True\n",
      "it True\n"
     ]
    }
   ],
   "source": [
    "def pronoun(entity):\n",
    "    return all([word['pos'] == \"PRON\" for word in entity])\n",
    "for antecedent in test:\n",
    "    print(list_to_string(antecedent), pronoun(antecedent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80aea859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Acura Integra True\n",
      "the lot False\n",
      "an Acura Integra False\n",
      "the lot False\n",
      "John True\n",
      "an Acura Integra False\n",
      "the lot False\n",
      "John True\n",
      "his Acura Integra False\n",
      "a bath False\n",
      "his Acura Integra False\n",
      "John True\n",
      "Susan False\n",
      "his new CD player False\n",
      "He True\n",
      "it False\n"
     ]
    }
   ],
   "source": [
    "def subject(entity):\n",
    "    return any([\"nsubj\" in word['dep'] for word in entity])\n",
    "for antecedent in test:\n",
    "    print(list_to_string(antecedent), subject(antecedent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f31b204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Acura Integra False\n",
      "the lot False\n",
      "an Acura Integra False\n",
      "the lot False\n",
      "John False\n",
      "an Acura Integra True\n",
      "the lot False\n",
      "John False\n",
      "his Acura Integra False\n",
      "a bath True\n",
      "his Acura Integra False\n",
      "John False\n",
      "Susan False\n",
      "his new CD player True\n",
      "He False\n",
      "it True\n",
      "She False\n",
      "herself False\n",
      "good advice True\n"
     ]
    }
   ],
   "source": [
    "def direct_object(entity):\n",
    "    return any([\"dobj\" in word['dep'] for word in entity])\n",
    "for antecedent in test:\n",
    "    print(list_to_string(antecedent), direct_object(antecedent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "213b2de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Acura Integra False\n",
      "the lot False\n",
      "an Acura Integra False\n",
      "the lot False\n",
      "John False\n",
      "an Acura Integra False\n",
      "the lot False\n",
      "John False\n",
      "his Acura Integra True\n",
      "a bath False\n",
      "his Acura Integra False\n",
      "John False\n",
      "Susan True\n",
      "his new CD player False\n",
      "He False\n",
      "it False\n",
      "She False\n",
      "herself True\n",
      "good advice False\n"
     ]
    }
   ],
   "source": [
    "def dative(entity):\n",
    "    return any([\"dative\" in word['dep'] for word in entity])\n",
    "for antecedent in test:\n",
    "    print(list_to_string(antecedent), dative(antecedent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "735d141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three apples they True\n",
      "good advice herself True\n",
      "three apples good advice False\n"
     ]
    }
   ],
   "source": [
    "def number(entity):\n",
    "    if pronoun(entity):\n",
    "        if entity[0]['word'] == 'they':\n",
    "            return \"p\"\n",
    "        else:\n",
    "            return \"s\"\n",
    "    else:\n",
    "        if any([word['tag'] == \"NNS\" for word in entity]):\n",
    "            return \"p\"\n",
    "        else:\n",
    "            return \"s\"\n",
    "\n",
    "def number_match(antecedent, target):\n",
    "    return number(antecedent) == number(target)\n",
    "\n",
    "print(list_to_string(test[-1]), list_to_string(test[-2]), number_match(test[-1], test[-2]))\n",
    "\n",
    "print(list_to_string(test[-3]), list_to_string(test[-4]), number_match(test[-3], test[-4]))\n",
    "print(list_to_string(test[-1]), list_to_string(test[-3]), number_match(test[-1], test[-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6137c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cec491c0-f473-4063-8833-7862c4168752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_vector(antecedent, target):\n",
    "    return {\n",
    "        \"exact_match\":exact_string_match(antecedent, target),\n",
    "        \"substring_match\":sub_string_match(antecedent, target),\n",
    "        \"word_overlap\":word_overlap_match(antecedent, target),\n",
    "        \"edit_distance\":edit_distance(list_to_string(antecedent), list_to_string(target)),\n",
    "        \"ant_definite\":definiteness(antecedent),\n",
    "        \"tar_defnite\":definiteness(target),\n",
    "        \"proper_noun\":proper_noun(antecedent) == proper_noun(target), \n",
    "        \"pronoun_antecedent\": pronoun(antecedent),\n",
    "        \"pronoun_target\": pronoun(target),\n",
    "        \"subject\": subject(target) == subject(antecedent),\n",
    "        \"direct_object\": direct_object(target) == direct_object(antecedent),\n",
    "        \"indirect_object\": dative(target) == dative(antecedent),\n",
    "        \"number_match\": number_match(antecedent, target),\n",
    "        #TODO gender, Animacy, Quotation \n",
    "        \n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd4c7f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"An Acura Integra is parked in the lot\",\n",
    "             \"There is an Acura Integra parked in the lot.\",\n",
    "             \"John parked an Acura Integra in the lot.\", \n",
    "             \"John gave his Acura Integra a bath\",\n",
    "             \"Inside his Acura Integra, John showed Susan his new CD player\",\n",
    "             \"He liked it a lot\",\n",
    "            \"She generally gave herself very good advice\",\n",
    "            \"they ate three apples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b4ab2b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'id': 0, 'word': 'An', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2},\n",
       "  {'id': 1,\n",
       "   'word': 'Acura',\n",
       "   'tag': 'NNP',\n",
       "   'dep': 'compound',\n",
       "   'pos': 'PROPN',\n",
       "   'head': 2},\n",
       "  {'id': 2,\n",
       "   'word': 'Integra',\n",
       "   'tag': 'NNP',\n",
       "   'dep': 'nsubjpass',\n",
       "   'pos': 'PROPN',\n",
       "   'head': 4}],\n",
       " [{'id': 6, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 7},\n",
       "  {'id': 7,\n",
       "   'word': 'lot',\n",
       "   'tag': 'NN',\n",
       "   'dep': 'pobj',\n",
       "   'pos': 'NOUN',\n",
       "   'head': 5}]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_potential_referents(sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0cee70d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = [\"John saw a beautiful Acura Integra at the dealership.\", \n",
    "            \"He showed it to Bob.\", \"He bought it.\"]\n",
    "\n",
    "john, integra, dealership = list(get_potential_referents(example1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe4a7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "he1, it1, _, bob = list(get_potential_referents(example1[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e66a1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "he2, it2 = list(get_potential_referents(example1[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23beb26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': False,\n",
       " 'substring_match': False,\n",
       " 'word_overlap': False,\n",
       " 'edit_distance': False,\n",
       " 'ant_definite': False,\n",
       " 'tar_defnite': False,\n",
       " 'proper_noun': False,\n",
       " 'pronoun_antecedent': False,\n",
       " 'pronoun_target': True,\n",
       " 'subject': True,\n",
       " 'direct_object': True,\n",
       " 'indirect_object': True}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector(john, he1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "69542698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': False,\n",
       " 'substring_match': False,\n",
       " 'word_overlap': False,\n",
       " 'edit_distance': False,\n",
       " 'ant_definite': False,\n",
       " 'tar_defnite': False,\n",
       " 'proper_noun': True,\n",
       " 'pronoun_antecedent': False,\n",
       " 'pronoun_target': True,\n",
       " 'subject': False,\n",
       " 'direct_object': False,\n",
       " 'indirect_object': True}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector(integra, he1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "871d26c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': False,\n",
       " 'substring_match': True,\n",
       " 'word_overlap': True,\n",
       " 'edit_distance': False,\n",
       " 'ant_definite': True,\n",
       " 'tar_defnite': False,\n",
       " 'proper_noun': True,\n",
       " 'pronoun_antecedent': False,\n",
       " 'pronoun_target': True,\n",
       " 'subject': False,\n",
       " 'direct_object': True,\n",
       " 'indirect_object': True}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector(dealership, he1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ce0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
