{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea9bb0a5-aa0e-4219-b3d8-0a4d9f261dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProbRobNLP import FeatureExtraction, logic, dialogue\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f43aa81-e265-429b-9aa6-b1752962d34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08858ab-77fd-4de0-8777-c6b5bf4a7878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector3D(0, 0, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = logic.Predicate(\"Vector3D\", 3)\n",
    "logic.Atom(p, [0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63adfd1f-a8d6-410e-b7ce-c46217651513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (det a N) \n",
    "# (amod red N)\n",
    "# (det the N)\n",
    "\n",
    "# N: [x=det][N(x)]\n",
    "# amod: A + N [A.ref = N.ref]\n",
    "# det: N(det=D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc9ea5d-946c-4baf-b1dd-4d83e076660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found match! 4 5\n",
      "0: {'id': 0, 'word': 'put', 'tag': 'VB', 'dep': 'ROOT', 'pos': 'VERB', 'head': 0, 'ref': {}, 'word_positions': [0]}\n",
      "1: {'id': 1, 'word': 'a', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2, 'ref': {}, 'word_positions': [1]}\n",
      "2: {'id': 2, 'word': 'table', 'tag': 'NN', 'dep': 'dobj', 'pos': 'NOUN', 'head': 0, 'ref': {}, 'word_positions': [2]}\n",
      "3: {'id': 3, 'word': 'on', 'tag': 'IN', 'dep': 'prep', 'pos': 'ADP', 'head': 0, 'ref': {}, 'word_positions': [3]}\n",
      "5: {'id': 5, 'word': 'the centre', 'tag': 'NN', 'dep': 'pobj', 'pos': 'NOUN', 'head': 3, 'ref': {}, 'word_positions': (4, 5), 'sem': [centre(0, 0, 0)][] h: {} f: {}}\n",
      "found match! 3 6\n",
      "0: {'id': 0, 'word': 'put', 'tag': 'VB', 'dep': 'ROOT', 'pos': 'VERB', 'head': 0, 'ref': {}, 'word_positions': [0]}\n",
      "1: {'id': 1, 'word': 'a', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2, 'ref': {}, 'word_positions': [1]}\n",
      "2: {'id': 2, 'word': 'block', 'tag': 'NN', 'dep': 'dobj', 'pos': 'NOUN', 'head': 0, 'ref': {}, 'word_positions': [2]}\n",
      "3: {'id': 3, 'word': 'to the left of', 'tag': 'IN', 'dep': 'prep', 'pos': 'ADP', 'head': 0, 'ref': {}, 'word_positions': (3, 4, 5, 6), 'sem': ['X0', 'X1'][left_of(X0, X1)] h: {'dobj': 'X0', 'pobj': 'X1'} f: {}}\n",
      "7: {'id': 7, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 8, 'ref': {}, 'word_positions': [7]}\n",
      "8: {'id': 8, 'word': 'tray', 'tag': 'NN', 'dep': 'pobj', 'pos': 'NOUN', 'head': 3, 'ref': {}, 'word_positions': [8]}\n",
      "0: {'id': 0, 'word': 'put', 'tag': 'VB', 'dep': 'ROOT', 'pos': 'VERB', 'head': 0, 'ref': {}, 'word_positions': [0]}\n",
      "1: {'id': 1, 'word': 'a', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2, 'ref': {}, 'word_positions': [1]}\n",
      "2: {'id': 2, 'word': 'cube', 'tag': 'NN', 'dep': 'dobj', 'pos': 'NOUN', 'head': 0, 'ref': {}, 'word_positions': [2]}\n",
      "3: {'id': 3, 'word': 'to', 'tag': 'IN', 'dep': 'prep', 'pos': 'ADP', 'head': 0, 'ref': {}, 'word_positions': [3]}\n",
      "4: {'id': 4, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 5, 'ref': {}, 'word_positions': [4]}\n",
      "5: {'id': 5, 'word': 'left', 'tag': 'NN', 'dep': 'pobj', 'pos': 'NOUN', 'head': 3, 'ref': {}, 'word_positions': [5]}\n",
      "6: {'id': 6, 'word': 'of', 'tag': 'IN', 'dep': 'prep', 'pos': 'ADP', 'head': 5, 'ref': {}, 'word_positions': [6]}\n",
      "7: {'id': 7, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 9, 'ref': {}, 'word_positions': [7]}\n",
      "8: {'id': 8, 'word': 'green', 'tag': 'JJ', 'dep': 'amod', 'pos': 'ADJ', 'head': 9, 'ref': {}, 'word_positions': [8]}\n",
      "9: {'id': 9, 'word': 'tray', 'tag': 'NN', 'dep': 'pobj', 'pos': 'NOUN', 'head': 6, 'ref': {}, 'word_positions': [9]}\n",
      "found match! 3 6\n",
      "0: {'id': 0, 'word': 'put', 'tag': 'VB', 'dep': 'ROOT', 'pos': 'VERB', 'head': 0, 'ref': {}, 'word_positions': [0]}\n",
      "1: {'id': 1, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2, 'ref': {}, 'word_positions': [1]}\n",
      "2: {'id': 2, 'word': 'camera', 'tag': 'NN', 'dep': 'dobj', 'pos': 'NOUN', 'head': 0, 'ref': {}, 'word_positions': [2]}\n",
      "3: {'id': 3, 'word': 'above', 'tag': 'IN', 'dep': 'prep', 'pos': 'ADP', 'head': 0, 'ref': {}, 'word_positions': [3]}\n",
      "4: {'id': 4, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 5, 'ref': {}, 'word_positions': [4]}\n",
      "5: {'id': 5, 'word': 'table', 'tag': 'NN', 'dep': 'pobj', 'pos': 'NOUN', 'head': 3, 'ref': {}, 'word_positions': [5]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0: {'id': 0, 'word': 'put the camera above the table', 'tag': 'VB', 'dep': 'ROOT', 'pos': 'VERB', 'head': 0, 'ref': {}, 'word_positions': (0, 1, 2, 3, 4, 5), 'sem': [X12, e1, X8][put(e1), above(X8, X12), table(X12), camera(X8)] h: {'dobj': X10} f: {'dobj': X8}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Rule:\n",
    "    pass\n",
    "\n",
    "\n",
    "class DRSish:\n",
    "\n",
    "    def __init__(self, ref, log, role=None, holes=None, fills=None):\n",
    "        self.ref = ref\n",
    "        self.log = log\n",
    "        self.role = role\n",
    "        self.holes = holes if holes is not None else {}\n",
    "        self.fills = fills if fills is not None else {}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.ref) + str(self.log) + ' h: ' + str(self.holes) + ' f: ' + str(self.fills)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        ref = list(set(self.ref + other.ref))\n",
    "        log = self.log + other.log\n",
    "        self.holes.update(other.holes)\n",
    "        self.fills.update(other.fills)\n",
    "        gaps_to_fill = [h for h in self.fills.keys() if h in self.holes]\n",
    "\n",
    "        # print('gaps to fill')\n",
    "        # print(gaps_to_fill)\n",
    "        \n",
    "        drs = DRSish(ref, log, holes=self.holes, fills = self.fills)\n",
    "        for g in gaps_to_fill:\n",
    "            drs.replace_reference(drs.holes[g], drs.fills[g])\n",
    "        # print(self.holes)\n",
    "        return drs\n",
    "\n",
    "    def get_predicates(self, reference):\n",
    "        assert (reference in self.ref)\n",
    "\n",
    "        for l in self.log:\n",
    "            if reference in l.refs:\n",
    "                yield l\n",
    "\n",
    "    def get_first_predicates(self, reference):\n",
    "        assert (reference in self.ref)\n",
    "\n",
    "        for l in self.log:\n",
    "            if reference == l.refs[0]:\n",
    "                yield l\n",
    "\n",
    "    def unify(self, other):\n",
    "\n",
    "        new_ref = []\n",
    "        log = copy.deepcopy(self.log)\n",
    "        assert (len(other.ref) == 1)\n",
    "        for ref in self.ref:\n",
    "\n",
    "            if isinstance(ref, str) and '<' in ref:\n",
    "\n",
    "                hole = ref.split('<')[1].strip('>')\n",
    "                if hole == other.role:\n",
    "                    new_ref.append(other.ref[0])\n",
    "                    new_log = []\n",
    "                    for formula in log:\n",
    "                        if ref in formula.refs:\n",
    "                            refs = [other.ref[0] if r == ref else r for r in formula.refs]\n",
    "                            new_log.append(sem(formula.name, refs))\n",
    "                        else:\n",
    "                            new_log.append(formula)\n",
    "                    log = new_log\n",
    "            else:\n",
    "                new_ref.append(ref)\n",
    "        new_ref = [r for r in new_ref if isinstance(r, str)]\n",
    "        return DRSish(new_ref, log + other.log, self.role)\n",
    "\n",
    "    def join_on_reference(self, other):\n",
    "        assert(len(self.ref) == len(other.ref))\n",
    "        \n",
    "        sref = self.ref\n",
    "        oref = other.ref\n",
    "        result = self + other\n",
    "        \n",
    "        for s, o in zip(sref, oref):\n",
    "            result.replace_reference(o, s)\n",
    "        return result\n",
    "    \n",
    "    def fill_gap(self, other, dep):\n",
    "        if dep in self.holes:\n",
    "            hole = self.holes.pop(dep)\n",
    "            result = self + other\n",
    "            result.replace_reference(hole, other.ref[0])\n",
    "        else:\n",
    "            self.fills[dep] = other.ref[0]\n",
    "            result = self + other\n",
    "        return result\n",
    "        \n",
    "    \n",
    "    def replace_reference(self, hole, antecedent):\n",
    "        new_ref = [r for r in self.ref if r != hole] + ([antecedent] if antecedent not in self.ref else [])\n",
    "        log = copy.deepcopy(self.log)\n",
    "        new_log = []\n",
    "        for l in log:\n",
    "            if hole in l.terms:\n",
    "                refs = [r if r != hole else antecedent for r in l.terms]\n",
    "                new_log.append(logic.Atom(l.pred, refs))\n",
    "            else:\n",
    "                new_log.append(l)\n",
    "        self.ref = new_ref\n",
    "        self.log = list(set(new_log))\n",
    "\n",
    "    def to_PRS(self):\n",
    "        order = self.order_prs()\n",
    "        entities = {entity.name: entity for entity in self._to_PRS()}\n",
    "        for name in order:\n",
    "            yield entities[name]\n",
    "\n",
    "    def remove_predicate(self, p):\n",
    "        self.log = [l for l in self.log if p != l]\n",
    "\n",
    "    def remove_reference(self, ref):\n",
    "        self.ref = [r for r in self.ref if r != ref]\n",
    "\n",
    "    def _to_PRS(self):\n",
    "        types = {'tray': 'Tray', 'cup': 'Cup', 'bowl': 'Bowl', 'bucket': 'Bucket',\n",
    "                 'chair': 'DiningChair', 'filled_cup': 'FilledCup',\n",
    "                 'plate': 'Plate', 'table': 'Table', 'robot': 'Robot', 'camera': 'Camera', 'peg': 'HexagonalPegBase',\n",
    "                 'gear': 'HexagonalGear', 'cube': 'Cube', 'toy_cube': 'ToyCube', 'cylinder': 'Cylinder',\n",
    "                 'rope link': 'RopeLink',\n",
    "                 'rope bucket': 'RopeBucket', 'conveyor belt': 'CircularConveyorBelt'}\n",
    "\n",
    "        two_place = {'on': probrob.OnConstraint, 'in': probrob.OnConstraint}\n",
    "\n",
    "        colour_dict = {'red': '\"0.1\"', 'blue': '\"0.2\"', 'green': '\"0.3\"', 'grey': '\"0.4\"', 'orange': '\"0.5\"',\n",
    "                       'purple': '\"0.7\"', 'pink': '\"0.6\"', 'black': '\"0\"', 'white': '\"1\"'}\n",
    "\n",
    "        # for l in self.log:\n",
    "        #     if l.name in special_names:\n",
    "        #         self.remove_predicate(l)\n",
    "        #         self.replace_reference(l.refs[0], l.name)\n",
    "        #         self.remove_reference(l.name)\n",
    "\n",
    "        for ref in self.ref:\n",
    "\n",
    "            preds = self.get_first_predicates(ref)\n",
    "\n",
    "            constraints = []\n",
    "            type_ = None\n",
    "            for pred in preds:\n",
    "                if pred.name in types:\n",
    "                    type_ = types[pred.name]\n",
    "                elif pred.name in two_place:\n",
    "                    constraints.append(two_place[pred.name](\n",
    "                        pred.refs[1] if pred.refs[1] not in special_names else special_names[pred.refs[1]]))\n",
    "                elif pred.name in colour_dict:\n",
    "                    constraints.append(probrob.PropConstraint('color', f'\"{pred.name}\"'))\n",
    "\n",
    "            if type_ is not None:\n",
    "                yield probrob.Entity(type_, ref, constraints)\n",
    "            else:\n",
    "                print(f'Warning: {ref} identified as type None')\n",
    "\n",
    "    def order_prs(self):\n",
    "        constraints = []\n",
    "        for entity in self._to_PRS():\n",
    "            for constraint in entity.constraints:\n",
    "                try:\n",
    "                    r = constraint.referent\n",
    "                    constraints.append((r, entity.name))\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "\n",
    "        constraint_dict = {}\n",
    "        for entity in self._to_PRS():\n",
    "            c = [d for (d, i) in constraints if i == entity.name and d in self.ref]\n",
    "            constraint_dict[entity.name] = c\n",
    "\n",
    "        order = []\n",
    "        i = 0\n",
    "        while len(constraint_dict) > 0 and i < 20:\n",
    "            print(constraint_dict)\n",
    "            new_dict = {}\n",
    "            for name, cons in constraint_dict.items():\n",
    "                if cons == [] or all([x in order for x in cons]):\n",
    "                    order.append(name)\n",
    "                else:\n",
    "                    new_dict[name] = cons\n",
    "            constraint_dict = new_dict\n",
    "            i += 1\n",
    "        return order\n",
    "\n",
    "    def draw(self):\n",
    "        prs_lines = self.to_PRS()\n",
    "        imp = probrob.Import('model', '*')\n",
    "        scene = probrob.WorldModel(prs_lines, [imp])\n",
    "        return scene\n",
    "\n",
    "    def test_reference_matches(self, reference, constraints):\n",
    "\n",
    "        preds = [c.name for c in self.get_first_predicates(reference)]\n",
    "        # print('reference', reference, 'preds', preds, 'constraints', constraints)\n",
    "        # print(all([c.name in preds for c in constraints]))\n",
    "        return all([c.name in preds for c in constraints])\n",
    "\n",
    "\n",
    "    def replace_specials(self):\n",
    "        \n",
    "        list_of_specials = {\n",
    "            'centre': logic.Atom(logic.Predicate('Vector3D'), [0, 0, 0]),\n",
    "            'left': logic.Atom(logic.Predicate('left', [])),\n",
    "        }\n",
    "    \n",
    "    \n",
    "class sem:\n",
    "    def __init__(self, name, refs):\n",
    "        self.name = name\n",
    "        self.refs = refs\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{str(self.name)}({\", \".join(map(str, self.refs))})'\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name and self.refs == other.refs\n",
    "\n",
    "    def __hash__(self):\n",
    "        # hash(custom_object)\n",
    "        return hash((self.name, ' '.join(map(str, self.refs))))\n",
    "\n",
    "\n",
    "     \n",
    "    \n",
    "class SExpression:\n",
    "    \n",
    "    def __init__(self, exp1, exp2, exp3):\n",
    "        self.exp1 = exp1\n",
    "        self.exp2 = exp2\n",
    "        self.exp3 = exp3\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'({self.exp1} {str(self.exp2)} {self.exp3})'\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.exp1 == other.exp1 and self.exp2 == other.exp2 and self.exp3 == other.exp3  \n",
    "    \n",
    "    @classmethod\n",
    "    def from_string(cls, s):\n",
    "        s = s.strip('()')\n",
    "        return SExpression(*s.split(' '))\n",
    "\n",
    "class Sentence:\n",
    "\n",
    "    def __init__(self, sentence):\n",
    "        self.sentence = {i: w for i, w in enumerate(FeatureExtraction.get_words_and_tags(sentence))}\n",
    "\n",
    "    def get_root(self):\n",
    "        for word in self.sentence.values():\n",
    "            if word['dep'] == 'ROOT':\n",
    "                return word\n",
    "        \n",
    "    def get_head(self):\n",
    "        for word in self.sentence.values():\n",
    "            if word['id'] == word['head']:\n",
    "                return word\n",
    "\n",
    "    def get_children(self, id_):\n",
    "        return [word for word in self.sentence.values() if word['head'] == id_ and word['id'] != id_]\n",
    "\n",
    "    def get_leaves(self):\n",
    "        heads = set([word['head'] for word in self.sentence.values()])\n",
    "        return [word for word in self.sentence.values() if word['id'] not in heads]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([f\"{i}: {w}\" for i, w in self.sentence.items()])\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.sentence.items()\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.sentence[item]\n",
    "    \n",
    "    def __setitem__(self, item, value):\n",
    "        self.sentence[item] = value\n",
    "    \n",
    "    def items(self):\n",
    "        return self.sentence.items()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentence)\n",
    "    \n",
    "    def get(self, key, default=None):\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError as e:\n",
    "            return default\n",
    "    \n",
    "    def join(self, head_id, child_id):\n",
    "        head = self.sentence[head_id]\n",
    "        child = self.sentence[child_id]\n",
    "\n",
    "        head_words = [(i, w) for i, w in zip(head['word_positions'], head['word'].split())]\n",
    "        child_words = [(i, w) for i, w in zip(child['word_positions'], child['word'].split())]\n",
    "        \n",
    "        new_words = sorted(head_words + child_words)\n",
    "        \n",
    "        ids, words = zip(*new_words)\n",
    "        \n",
    "        head['word'] = ' '.join(words)\n",
    "        head['word_positions'] = ids\n",
    "\n",
    "        self[head_id] = head\n",
    "\n",
    "        self.sentence = {id_: word for id_, word in self.items()\n",
    "                     if not (word['head'] == head['id'] and word['word'] in head['word']) or word['dep'] == 'ROOT'}\n",
    "        \n",
    "        for key, word in self.items():\n",
    "            if word['head'] == child['id']:\n",
    "                word['head'] = head['id']\n",
    "    \n",
    "def binarize(sentence):\n",
    "    s = Sentence(sentence)\n",
    "    \n",
    "    return s\n",
    "\n",
    "# s1 = SExpression('dobj', 'acquired', 'Pixar')\n",
    "# print(s1)\n",
    "# s2 = SExpression('nsubj', s1, 'Disney')\n",
    "# print(s2)\n",
    "\n",
    "# print(SExpression.from_string('(dobj acquired Pixar)'))\n",
    "\n",
    "# assert(SExpression.from_string('(dobj acquired Pixar)') == s1)\n",
    "\n",
    "\n",
    "dialogue.reset_reference()\n",
    "dialogue.reset_variable()\n",
    "dialogue.reset_event()\n",
    "\n",
    "multiword_expressions = {\n",
    "    ('the', 'centre'): (lambda: DRSish([logic.Atom(logic.Predicate('centre', 3), [0, 0, 0])], []), 0, 1),\n",
    "    ('to', 'the', 'left', 'of'): (lambda x, y: DRSish([x, y], [logic.Atom(logic.Predicate('left_of', 2), [x,y])], holes={'dobj':x, 'pobj':y}), 2, 0),\n",
    "    ('to', 'the', 'right', 'of'): (lambda x, y: DRSish([x, y], [logic.Atom(logic.Predicate('right_of', 2), [x,y])], holes={'dobj':x, 'pobj':y}), 2, 0)}\n",
    "\n",
    "\n",
    "def combine_multword_expression(sentence, expression, start_location):\n",
    "    words = [sentence[i] for i in range(start_location, start_location+len(expression))]\n",
    "    heads = [w['head'] for w in words]\n",
    "    leaves = [w for w in words if w['id'] not in heads]\n",
    "    while leaves != []:\n",
    "        next_one = leaves[0]\n",
    "        sentence.join(next_one['head'], next_one['id'])\n",
    "        words.remove(next_one)\n",
    "        heads = [w['head'] for w in words]\n",
    "        leaves = [w for w in words if w['id'] not in heads]\n",
    "    return sentence, [words[0]]\n",
    "        \n",
    "\n",
    "def match_multiword_expression(sentence, multiword_expression, semantics):\n",
    "    drs_lambda, num_variables, head_position = semantics\n",
    "    for i in range(len(sentence)):\n",
    "        if all([sentence.get(i+j, {}).get('word', '') == word for j, word in enumerate(multiword_expression)]):\n",
    "            print(\"found match!\", i, i+len(multiword_expression)-1)\n",
    "            \n",
    "            for j in range(i, i+len(multiword_expression)):\n",
    "                if j != i+head_position:\n",
    "                    sentence.join(sentence[j]['head'], j)\n",
    "            drs = drs_lambda(*[dialogue.get_variable() for i in range(num_variables)])\n",
    "            sentence[i+head_position]['sem'] = drs\n",
    "    return sentence\n",
    "                \n",
    "\n",
    "s = Sentence('put a table on the centre')\n",
    "print(match_multiword_expression(s, ('the', 'centre'), (lambda: DRSish([logic.Atom(logic.Predicate('centre', 3), [0, 0, 0])], []), 0, 1)))\n",
    "\n",
    "s = Sentence('put a block to the left of the tray')\n",
    "print(match_multiword_expression(s, ('to', 'the', 'left', 'of'), multiword_expressions[('to', 'the', 'left', 'of')]))\n",
    "\n",
    "\n",
    "def substitution(sentence):\n",
    "    \n",
    "    for expression, semantics in multiword_expressions.items():\n",
    "        sentence = match_multiword_expression(sentence, expression, semantics)\n",
    "    \n",
    "    for id_, word in sentence.items():\n",
    "        if len(word['word'].split()) > 1:\n",
    "            continue\n",
    "        elif word['tag'] == 'DT':\n",
    "            if word['word'] == 'a':\n",
    "                word['sem'] = DRSish([logic.Constant(dialogue.get_reference())], [])\n",
    "            elif word['word'] == 'the':\n",
    "                word['sem'] = DRSish([logic.Variable(dialogue.get_variable())], [])\n",
    "        elif word['tag'] in ['NN', 'JJ']:\n",
    "            variable = logic.Variable(dialogue.get_variable())\n",
    "            p = logic.Predicate(word['word'], 1)\n",
    "            a = logic.Atom(p, [variable])\n",
    "            word['sem'] = DRSish([variable], [a])\n",
    "        \n",
    "        elif word['tag'] == 'IN':\n",
    "            x = logic.Variable(dialogue.get_variable())\n",
    "            y = logic.Variable(dialogue.get_variable())\n",
    "            p = logic.Predicate(word['word'], 2)\n",
    "            a = logic.Atom(p, [x, y])\n",
    "            word['sem'] = DRSish([x, y], [a], holes={'dobj':x, 'pobj':y})\n",
    "        \n",
    "        elif word['tag'] == 'VB':\n",
    "            e = logic.Constant(dialogue.get_event())\n",
    "            p = logic.Predicate(word['word'], 1)\n",
    "            a = logic.Atom(p, [e])\n",
    "            word['sem'] = DRSish([e], [a])\n",
    "            \n",
    "        elif word['tag'] == 'PRP':\n",
    "            x = logic.Variable(dialogue.get_variable())\n",
    "            word['sem'] = DRSish([x], [])\n",
    "        \n",
    "    return sentence\n",
    "\n",
    "rules = {'amod': lambda head, child: head.join_on_reference(child),\n",
    "         'det': lambda head, child: child.join_on_reference(head), \n",
    "         'pobj': lambda head, child: head.fill_gap(child, 'pobj'), \n",
    "         'prep': lambda head, child: head + child,\n",
    "         'dobj': lambda head, child: head.fill_gap(child, 'dobj'),}\n",
    "\n",
    "\n",
    "def compose(sentence, position):\n",
    "    child = sentence.sentence[position]\n",
    "    head_id = child['head']\n",
    "    head = sentence.sentence[head_id]\n",
    "    \n",
    "    dep = child['dep']\n",
    "    \n",
    "    sem_child = child['sem']\n",
    "    sem_head = head['sem']\n",
    "    \n",
    "#     print(head, child)\n",
    "#     print(sem_head, sem_child)\n",
    "    new_sem = rules[dep](sem_head, sem_child)\n",
    "    \n",
    "    sentence.sentence[head_id]['sem'] = new_sem\n",
    "    sentence.join(head_id, child['id'])\n",
    "    return sentence\n",
    "\n",
    "def parse_sentence(s):\n",
    "    s = Sentence(s)\n",
    "    print(s)\n",
    "    s = substitution(s)\n",
    "    \n",
    "    \n",
    "    while ((leaves := s.get_leaves()) != []):\n",
    "        l = leaves[0]\n",
    "        # print('composing')\n",
    "        # print(l, l['sem'].holes, l['sem'].fills)\n",
    "        h = s.sentence[l['head']]\n",
    "        # print(h, h['sem'].holes, h['sem'].fills)\n",
    "        # print()\n",
    "        compose(s, l['id'])\n",
    "        # print(s)\n",
    "        # print()\n",
    "        # print()\n",
    "    return s\n",
    "\n",
    "# s = binarize('put a red block on the table')\n",
    "# out = substitution(s)\n",
    "\n",
    "# compose(s, 2)\n",
    "\n",
    "# compose(s, 1)\n",
    "\n",
    "# compose(s, 5)\n",
    "\n",
    "# compose(s, 6)\n",
    "\n",
    "# compose(s, 4)\n",
    "\n",
    "# out = compose(s, 3)\n",
    "# out\n",
    "\n",
    "\n",
    "\n",
    "# s = 'put a red block on the table'\n",
    "# parse_sentence(s)\n",
    "\n",
    "# s = 'add a table to the centre'\n",
    "# parse_sentence(s)\n",
    "\n",
    "# s = 'a table'\n",
    "# parse_sentence(s)\n",
    "\n",
    "# s = 'put a tray on it'\n",
    "# parse_sentence(s)\n",
    "\n",
    "s = 'put a cube to the left of the green tray'\n",
    "r = parse_sentence(s)\n",
    "r\n",
    "\n",
    "s = 'put the camera above the table'\n",
    "r = parse_sentence(s)\n",
    "r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67548b8-b4a3-46ef-bd74-c9b89619cef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb927a4-e282-487f-b791-b3d8d87b8f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf97070-51f7-4716-9bb7-006ea245b5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'put a cube to the left of the green tray'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "968c6a0c-fa9d-46f0-8b8a-829b07d7e1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "a.remove(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "41297dac-e9ff-4172-8a2b-f879aaf8de3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: {'id': 0, 'word': 'add', 'tag': 'VB', 'dep': 'ROOT', 'pos': 'VERB', 'head': 0, 'ref': {}, 'word_positions': [0]}\n",
      "1: {'id': 1, 'word': 'a', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 2, 'ref': {}, 'word_positions': [1]}\n",
      "2: {'id': 2, 'word': 'cube', 'tag': 'NN', 'dep': 'dobj', 'pos': 'NOUN', 'head': 0, 'ref': {}, 'word_positions': [2]}\n",
      "3: {'id': 3, 'word': 'to', 'tag': 'IN', 'dep': 'prep', 'pos': 'ADP', 'head': 0, 'ref': {}, 'word_positions': [3]}\n",
      "4: {'id': 4, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 5, 'ref': {}, 'word_positions': [4]}\n",
      "5: {'id': 5, 'word': 'left', 'tag': 'NN', 'dep': 'pobj', 'pos': 'NOUN', 'head': 3, 'ref': {}, 'word_positions': [5]}\n",
      "6: {'id': 6, 'word': 'of', 'tag': 'IN', 'dep': 'prep', 'pos': 'ADP', 'head': 5, 'ref': {}, 'word_positions': [6]}\n",
      "7: {'id': 7, 'word': 'the', 'tag': 'DT', 'dep': 'det', 'pos': 'DET', 'head': 8, 'ref': {}, 'word_positions': [7]}\n",
      "8: {'id': 8, 'word': 'tray', 'tag': 'NN', 'dep': 'pobj', 'pos': 'NOUN', 'head': 6, 'ref': {}, 'word_positions': [8]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0: {'id': 0, 'word': 'add a cube to the left of the tray', 'tag': 'VB', 'dep': 'ROOT', 'pos': 'VERB', 'head': 0, 'ref': {}, 'word_positions': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'sem': [e0, X1, X3, x0, X7][cube(x0), to(X1, X7), left(X3), tray(X7), add(e0), of(x0, X7)] r: None}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'add a cube to the left of the tray'\n",
    "parse_sentence(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf234aff-bcea-4a44-94eb-91d2e5dfb585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0: {'id': 0, 'word': 'put on the table', 'tag': 'VB', 'dep': 'ROOT', 'pos': 'VERB', 'head': 0, 'ref': {}, 'sem': [X4, e0, X2][put(e0), on(X2, X4), table(X4)] r: None}\n",
       "3: {'id': 3, 'word': 'a red block', 'tag': 'NN', 'dep': 'dobj', 'pos': 'NOUN', 'head': 0, 'ref': {}, 'sem': [x0][red(x0), block(x0)] r: None}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "30b825af-9fb7-4a8e-9a8c-7e106a1af4fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-9cfd414b2f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sem'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sem'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "red = out.sentence[2]['sem']\n",
    "block = out.sentence[3]['sem']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dcb4323-ac2d-4afa-9af3-6dc8248e8271",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1f8697931afe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_on_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-b1d48e1563e6>\u001b[0m in \u001b[0;36mjoin_on_reference\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin_on_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0msref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "block.join_on_reference(red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1187fd-5309-4a9a-b561-82cb281ed39c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
